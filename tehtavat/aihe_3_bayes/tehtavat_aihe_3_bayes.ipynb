{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Koneoppiminen: Tehtävä 3: Naiivi Bayes-luokittelija (max. 9p)\n",
    "\n",
    "Aiheena **Naiivi Bayes -luokittelija**: Naiivit Bayes on ohjattu oppimismenetelmä, joka perustuu Bayesin lauseen soveltamiseen \"naiivilla\" oletuksella ehdollisesta riippumattomuudesta jokaisen ominaisuuden välillä. Huolimatta näennäisesti yksinkertaistetuista oletuksistaan, naiivit Bayes-luokittelijat ovat toimineet hyvin monissa todellisissa tilanteissa, kuuluisa dokumenttien luokittelussa ja roskapostin suodatuksessa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Muista** kirjoittaa alle omat tietosi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:47:18.853963Z",
     "start_time": "2024-08-21T11:47:18.832022Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "student_info"
    ]
   },
   "outputs": [],
   "source": [
    "# Kirjoita tähän tietosi!\n",
    "student_name = 'Jere Soininen'\n",
    "student_id = 'AB6802'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Tutki tehtävää varten myös seuraavat scikit Learn -manuaalisivut:\n",
    "* [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "* [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tehtävä 3.1\n",
    "### Aihe: Wine Data Set (3 pistettä)\n",
    "\n",
    "Toteuta tehtävä seuraavasti:\n",
    "\n",
    "1. Tutustu *Wine Data Set* -aineistoon osoitteessa [https://archive.ics.uci.edu/ml/datasets/Wine](https://archive.ics.uci.edu/ml/datasets/Wine) .\n",
    "\n",
    "2. Lataa aineisto ja aseta sarakkeiden nimet. \n",
    "\n",
    "3. Jaa aineisto koulutus- ja testausaineistoon käyttäen `scikit-learn`-kirjaston [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)-funktiota.  \n",
    "\n",
    "4. Skaalaa koulutusaineiston sarakkeet välille 0...1 `scikit-learn`-kirjaston `preprocessing`-moduulin [minmax_scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.minmax_scale.html#sklearn.preprocessing.minmax_scale)-funktiolla.\n",
    "\n",
    "* Tallenna koulutusaineisto ja sen luokkamuuttuja muuttujiin `X_train`, `y_train`,\n",
    "* Tallenna testausaineisto vastaavasti muuttujiin `X_test`, `y_test`.\n",
    "\n",
    "Aseta testausjoukon kooksi `33%` ja satunnaisuuden siemeneksi `2120`.\n",
    "\n",
    "Vinkit:\n",
    "* Vinkki: älä skaalaa luokkamuuttujaa.\n",
    "* Vinkki: luokkamuuttujaa ei saa tallentaa `X`-muuttujiin.\n",
    "\n",
    "Muuttujien nimeämisestä: \n",
    "\n",
    "* X-alkuiset muuttujat ovat ominaisuuksia, joita käytetään mallin syötteenä (input). \n",
    "* Y-alkuiset muuttujat ovat odotettuja tuloksia (labels).\n",
    "* `X_train` ja `X_test` muuttujissa aineisto (dataset) on käytännössä vain jaettu (split) mallin koulutusta ja testaamista varten. \n",
    "* `y_train` ja `y_test` muuttujissa ovat vastaavasti odotetut tulokset (luokkamuuttujan).\n",
    "\n",
    "Koulutus- ja testiaineiston ei tule sisältää samoja datarivejä. Eikä koskaan myöskään luokkamuuttujaa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:47:20.381877Z",
     "start_time": "2024-08-21T11:47:18.860945Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Kirjoita toteutuksesi tähän soluun.\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../../data/wine/wine.data', header=None)\n",
    "\n",
    "# TODO: Sarakkeiden nimeäminen.\n",
    "columns = [\n",
    "    'cultivar', 'alcohol', 'malic-acid', 'ash', 'alcalinity-of-ash', 'magnesium', 'total-phenols',\n",
    "    'flavanoids', 'nonflavanoid-phenols', 'proanthocyanins', 'color-intensity',\n",
    "    'hue', 'od280-od315-diluted-wines', 'proline'\n",
    "]\n",
    "\n",
    "df.columns = columns\n",
    "\n",
    "X = df.drop(columns=['cultivar'])\n",
    "y = df['cultivar']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=2120)\n",
    "\n",
    "mms = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train = pd.DataFrame(mms.transform(X_train), columns=X.columns)\n",
    "X_test = pd.DataFrame(mms.transform(X_test), columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:47:20.428752Z",
     "start_time": "2024-08-21T11:47:20.392847Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "answer_3_1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train columns: Index(['alcohol', 'malic-acid', 'ash', 'alcalinity-of-ash', 'magnesium',\n",
      "       'total-phenols', 'flavanoids', 'nonflavanoid-phenols',\n",
      "       'proanthocyanins', 'color-intensity', 'hue',\n",
      "       'od280-od315-diluted-wines', 'proline'],\n",
      "      dtype='object')\n",
      "X_train:       alcohol  malic-acid       ash  alcalinity-of-ash  magnesium  \\\n",
      "0    0.444737    0.175153  0.491979           0.613402   0.152174   \n",
      "1    0.139474    0.236253  1.000000           0.922680   0.532609   \n",
      "2    0.342105    0.020367  0.315508           0.216495   0.717391   \n",
      "3    0.344737    0.317719  0.588235           0.536082   0.304348   \n",
      "4    0.721053    0.205703  0.705882           0.335052   0.489130   \n",
      "..        ...         ...       ...                ...        ...   \n",
      "114  0.394737    0.940937  0.684492           0.742268   0.282609   \n",
      "115  0.507895    0.521385  0.529412           0.407216   0.391304   \n",
      "116  0.581579    0.346232  0.807487           0.536082   0.521739   \n",
      "117  0.431579    0.018330  0.470588           0.381443   0.315217   \n",
      "118  0.813158    0.120163  0.513369           0.319588   0.271739   \n",
      "\n",
      "     total-phenols  flavanoids  nonflavanoid-phenols  proanthocyanins  \\\n",
      "0         0.137931    0.299578              0.660377         0.425087   \n",
      "1         0.758621    1.000000              0.641509         0.508711   \n",
      "2         0.317241    0.318565              0.415094         0.818815   \n",
      "3         0.544828    0.373418              0.396226         0.313589   \n",
      "4         0.696552    0.516878              0.490566         0.442509   \n",
      "..             ...         ...                   ...              ...   \n",
      "114       0.279310    0.054852              0.943396         0.240418   \n",
      "115       0.141379    0.075949              0.509434         0.184669   \n",
      "116       0.627586    0.495781              0.490566         0.491289   \n",
      "117       0.420690    0.337553              0.320755         0.365854   \n",
      "118       0.420690    0.440928              0.245283         0.404181   \n",
      "\n",
      "     color-intensity       hue  od280-od315-diluted-wines   proline  \n",
      "0           0.138544  0.325203                   0.416974  0.149786  \n",
      "1           0.378330  0.365854                   0.885609  0.133381  \n",
      "2           0.147425  0.471545                   0.376384  0.336662  \n",
      "3           0.094139  0.260163                   0.771218  0.114123  \n",
      "4           0.404973  0.528455                   0.605166  0.782454  \n",
      "..               ...       ...                        ...       ...  \n",
      "114         0.289520  0.276423                   0.147601  0.169044  \n",
      "115         0.314387  0.162602                   0.169742  0.283167  \n",
      "116         0.229130  0.455285                   0.605166  0.325963  \n",
      "117         0.078153  0.609756                   0.690037  0.122682  \n",
      "118         0.289520  0.560976                   0.564576  0.714693  \n",
      "\n",
      "[119 rows x 13 columns]\n",
      "X_test:      alcohol  malic-acid       ash  alcalinity-of-ash  magnesium  \\\n",
      "0   0.423684    0.095723  0.352941           0.319588   0.326087   \n",
      "1   0.457895    0.517312  0.331551           0.278351   0.108696   \n",
      "2   0.644737    0.187373  0.561497           0.510309   0.326087   \n",
      "3   0.100000   -0.030550  0.609626           0.536082   0.195652   \n",
      "4   0.352632    0.057026  0.299465           0.463918   0.086957   \n",
      "5   0.700000    0.482688  0.631016           0.484536   0.402174   \n",
      "6   0.560526    0.545825  0.422460           0.536082   0.347826   \n",
      "7   0.113158    0.580448  0.245989           0.458763   0.402174   \n",
      "8   0.331579    0.464358  0.454545           0.381443   0.195652   \n",
      "9   0.300000    0.114053  0.625668           0.432990   0.369565   \n",
      "10  0.744737    0.126273  0.700535           0.742268   0.173913   \n",
      "11  0.321053    0.780041  0.631016           0.536082   0.206522   \n",
      "12  0.686842    0.450102  0.641711           0.237113   0.500000   \n",
      "13  0.884211    0.199593  0.582888           0.206186   0.282609   \n",
      "14  0.478947    0.144603  0.620321           0.371134   0.271739   \n",
      "15  0.307895    0.435845  0.513369           0.432990   0.282609   \n",
      "16  0.373684    0.435845  0.684492           0.845361   0.293478   \n",
      "17  0.444737    0.187373  0.449198           0.422680   0.173913   \n",
      "18  0.713158    0.158859  0.475936           0.298969   0.521739   \n",
      "19  0.476316    0.421589  0.668449           0.690722   0.336957   \n",
      "20  0.276316    0.048880  0.614973           0.690722   0.086957   \n",
      "21  0.589474    0.690428  0.481283           0.484536   0.543478   \n",
      "22  0.165789    0.201629  0.299465           0.278351   0.293478   \n",
      "23  0.684211    0.187373  0.716578           0.340206   0.456522   \n",
      "24  0.621053    0.179226  0.673797           0.283505   0.250000   \n",
      "25  0.750000    0.203666  0.657754           0.226804   0.336957   \n",
      "26  0.650000    0.454175  0.673797           0.690722   0.576087   \n",
      "27  0.878947    0.215886  0.609626           0.319588   0.467391   \n",
      "28  0.207895    0.169043  0.278075           0.458763   0.173913   \n",
      "29  0.707895    0.109980  0.609626           0.314433   0.413043   \n",
      "30  0.389474    0.071283  0.475936           0.355670   0.163043   \n",
      "31  0.531579    0.154786  0.636364           0.381443   0.304348   \n",
      "32  0.539474    0.613035  0.534759           0.561856   0.467391   \n",
      "33  0.407895    0.081466  0.395722           0.484536   0.358696   \n",
      "34  0.457895    0.305499  0.491979           0.458763   0.173913   \n",
      "35  0.755263    0.160896  0.406417           0.278351   0.336957   \n",
      "36  0.155263    0.224033  0.491979           0.381443   0.304348   \n",
      "37  0.602632    0.478615  0.545455           0.561856   0.239130   \n",
      "38  0.255263    0.517312  0.342246           0.432990   0.184783   \n",
      "39  0.697368    0.191446  0.534759           0.340206   0.369565   \n",
      "40  0.786842    0.160896  0.454545           0.278351   0.282609   \n",
      "41  0.152632    0.093686  0.716578           0.484536   0.260870   \n",
      "42  0.807895    0.258656  0.502674           0.381443   0.380435   \n",
      "43  0.594737    0.219959  0.705882           0.319588   0.347826   \n",
      "44  0.468421    0.289206  0.556150           0.690722   0.304348   \n",
      "45  0.860526    0.209776  0.727273           0.484536   0.543478   \n",
      "46  0.842105    0.167006  0.572193           0.257732   0.619565   \n",
      "47  0.613158    0.340122  0.529412           0.484536   0.206522   \n",
      "48  0.739474    0.657841  0.545455           0.458763   0.206522   \n",
      "49  0.163158    0.158859  0.673797           0.793814   0.195652   \n",
      "50  0.807895    0.230143  0.556150           0.422680   0.358696   \n",
      "51  0.839474    0.164969  0.502674           0.293814   0.521739   \n",
      "52  0.623684    0.755601  0.802139           0.742268   0.456522   \n",
      "53  0.221053    0.696538  0.550802           0.536082   0.130435   \n",
      "54  0.652632    0.185336  0.689840           0.432990   0.434783   \n",
      "55  0.531579    0.179226  0.395722           0.329897   0.402174   \n",
      "56  0.718421    0.130346  0.716578           0.458763   0.673913   \n",
      "57  0.331579    0.395112  0.459893           0.381443   0.195652   \n",
      "58  0.834211    0.177189  0.582888           0.237113   0.456522   \n",
      "\n",
      "    total-phenols  flavanoids  nonflavanoid-phenols  proanthocyanins  \\\n",
      "0        0.358621    0.225738              0.754717         0.073171   \n",
      "1        0.224138    0.191983              0.566038         0.146341   \n",
      "2        0.593103    0.556962              0.245283         0.505226   \n",
      "3        0.517241    0.352321              0.547170         0.358885   \n",
      "4        0.389655    0.350211              0.264151         0.219512   \n",
      "5        0.293103    0.046414              0.698113         0.135889   \n",
      "6        0.179310    0.044304              0.566038         0.310105   \n",
      "7        0.758621    0.472574              0.207547         1.104530   \n",
      "8        0.644828    0.559072              0.603774         0.836237   \n",
      "9        0.313793    0.297468              0.603774         0.216028   \n",
      "10       0.679310    0.531646              0.150943         0.508711   \n",
      "11       0.137931    0.027426              0.754717         0.135889   \n",
      "12       0.593103    0.567511              0.075472         0.435540   \n",
      "13       0.524138    0.459916              0.320755         0.547038   \n",
      "14       0.517241    0.428270              0.245283         0.365854   \n",
      "15       0.093103    0.031646              0.509434         0.111498   \n",
      "16       0.317241    0.050633              0.943396         0.254355   \n",
      "17       0.420690    0.462025              0.245283         0.473868   \n",
      "18       0.558621    0.540084              0.150943         0.421603   \n",
      "19       0.462069    0.054852              0.754717         0.139373   \n",
      "20       0.351724    0.261603              0.509434         0.344948   \n",
      "21       0.210345    0.073840              0.566038         0.327526   \n",
      "22       0.217241    0.259494              0.396226         0.257840   \n",
      "23       0.644828    0.542194              0.320755         0.365854   \n",
      "24       0.644828    0.548523              0.396226         0.362369   \n",
      "25       0.782759    0.679325              0.075472         0.449477   \n",
      "26       0.144828    0.259494              0.169811         0.292683   \n",
      "27       0.989655    0.664557              0.207547         0.616725   \n",
      "28       0.524138    0.274262              0.452830         0.351916   \n",
      "29       0.834483    0.702532              0.113208         0.567944   \n",
      "30       0.351724    0.050633              0.886792         0.292683   \n",
      "31       0.506897    0.440928              0.301887         0.358885   \n",
      "32       0.148276    0.221519              0.396226         0.254355   \n",
      "33       0.172414    0.050633              0.754717         0.344948   \n",
      "34       0.141379    0.035865              0.660377         0.080139   \n",
      "35       0.731034    0.643460              0.150943         0.602787   \n",
      "36       0.703448    0.405063              0.075472         0.327526   \n",
      "37       0.327586    0.088608              0.603774         0.292683   \n",
      "38       0.351724    0.274262              0.452830         0.508711   \n",
      "39       0.496552    0.495781              0.547170         0.543554   \n",
      "40       0.575862    0.419831              0.245283         0.547038   \n",
      "41       0.606897    0.544304              0.301887         0.724739   \n",
      "42       0.679310    0.628692              0.169811         0.686411   \n",
      "43       0.696552    0.609705              0.339623         0.435540   \n",
      "44       0.058621    0.158228              0.264151         0.146341   \n",
      "45       0.627586    0.590717              0.377358         0.543554   \n",
      "46       0.627586    0.573840              0.283019         0.655052   \n",
      "47       0.144828    0.033755              0.452830         0.080139   \n",
      "48       0.282759    0.103376              0.660377         0.400697   \n",
      "49       0.324138    0.267932              0.509434         0.324042   \n",
      "50       0.610345    0.544304              0.358491         0.686411   \n",
      "51       0.765517    0.561181              0.245283         0.564460   \n",
      "52       0.344828    0.130802              0.264151         0.243902   \n",
      "53       0.648276    0.567511              0.150943         0.871080   \n",
      "54       0.472414    0.462025              0.301887         0.393728   \n",
      "55       0.696552    0.561181              0.283019         0.564460   \n",
      "56       0.679310    0.506329              0.698113         0.327526   \n",
      "57       0.506897    0.402954              0.226415         0.550523   \n",
      "58       0.789655    0.643460              0.396226         0.543554   \n",
      "\n",
      "    color-intensity       hue  od280-od315-diluted-wines   proline  \n",
      "0          0.356128  0.406504                   0.110701  0.122682  \n",
      "1          0.147425  0.178862                   0.306273  0.067047  \n",
      "2          0.298401  0.455285                   0.804428  0.457917  \n",
      "3          0.119005  0.504065                   0.376384  0.111270  \n",
      "4          0.261101  0.520325                   0.808118  0.165478  \n",
      "5          0.367673  0.390244                   0.195572  0.286733  \n",
      "6          0.200710  0.097561                   0.143911  0.393723  \n",
      "7          0.103020  0.219512                   0.560886  0.202568  \n",
      "8          0.049734  0.764228                   0.568266  0.091298  \n",
      "9          0.107460  0.788618                   0.346863  0.054922  \n",
      "10         0.145648  0.715447                   0.690037  0.094151  \n",
      "11         0.187389  0.219512                  -0.007380  0.315264  \n",
      "12         0.298401  0.390244                   0.763838  0.404422  \n",
      "13         0.311723  0.439024                   0.845018  0.721826  \n",
      "14         0.194494  0.495935                   0.863469  0.525678  \n",
      "15         0.333925  0.146341                   0.199262  0.165478  \n",
      "16         0.511545  0.154472                   0.162362  0.429387  \n",
      "17         0.191829  0.552846                   0.682657  0.310984  \n",
      "18         0.365009  0.357724                   0.704797  0.557775  \n",
      "19         0.282416  0.333333                   0.317343  0.222539  \n",
      "20         0.040853  0.674797                   0.527675  0.251070  \n",
      "21         0.751332  0.089431                   0.099631  0.397290  \n",
      "22         0.182948  0.609756                   0.313653  0.106990  \n",
      "23         0.493783  0.650407                   0.586716  0.736091  \n",
      "24         0.271758  0.357724                   0.712177  0.654066  \n",
      "25         0.327709  0.325203                   0.837638  0.582739  \n",
      "26         0.609236  0.089431                   0.003690  0.158345  \n",
      "27         0.538188  0.308943                   0.797048  0.857347  \n",
      "28         0.028419  0.373984                   0.424354  0.097718  \n",
      "29         0.449378  0.333333                   0.583026  0.718260  \n",
      "30         0.329485  0.219512                   0.081181  0.265335  \n",
      "31         0.222913  0.520325                   0.450185  0.589872  \n",
      "32         0.680284  0.073171                   0.014760  0.194009  \n",
      "33         0.520426  0.081301                   0.095941  0.258203  \n",
      "34         0.724689  0.073171                   0.125461  0.136947  \n",
      "35         0.387211  0.349593                   0.752768  0.504280  \n",
      "36         0.134103  0.552846                   0.616236  0.047789  \n",
      "37         0.593250  0.056911                   0.121771  0.265335  \n",
      "38        -0.040853  0.365854                   0.649446  0.203994  \n",
      "39         0.186501  0.609756                   0.583026  0.507846  \n",
      "40         0.262877  0.455285                   0.848708  0.539943  \n",
      "41         0.080817  0.390244                   0.726937  0.286733  \n",
      "42         0.356128  0.626016                   0.693727  0.878745  \n",
      "43         0.378330  0.479675                   0.571956  0.707561  \n",
      "44         0.351687  0.146341                   0.025830  0.201141  \n",
      "45         0.396092  0.479675                   0.501845  0.714693  \n",
      "46         0.346359  0.455285                   0.970480  0.561341  \n",
      "47         0.342806  0.178862                   0.435424  0.358060  \n",
      "48         0.645648  0.073171                   0.129151  0.144080  \n",
      "49         0.076377  0.715447                   0.708487  0.202568  \n",
      "50         0.396092  0.479675                   0.538745  0.557775  \n",
      "51         0.412078  0.373984                   0.745387  0.493581  \n",
      "52         0.600355  0.154472                   0.232472  0.251070  \n",
      "53         0.094139  0.219512                   0.867159  0.072753  \n",
      "54         0.218472  0.504065                   0.583026  0.582739  \n",
      "55         0.293073  0.325203                   0.760148  0.432953  \n",
      "56         0.325044  0.626016                   0.630996  0.682596  \n",
      "57         0.036412  0.544715                   0.741697  0.008559  \n",
      "58         0.444938  0.463415                   0.575646  0.835949  \n"
     ]
    }
   ],
   "source": [
    "# Tehtävän vastaukset. Huom! Älä muokkaa tätä solua, vaan aja se, kun olet suorittanut tehtävän. \n",
    "# Tallenna vastauksesi X_train- X_test-muuttujiin.\n",
    "print(f'X_train columns: {X_train.columns}')\n",
    "print(f'X_train: {X_train}')\n",
    "print(f'X_test: {X_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tehtävä 3.2\n",
    "### Aihe: Gaussian Naive Bayes (2 pistettä)\n",
    "\n",
    "Käytä `scikit-learn`-kirjastosta löytyvää *Gaussian Naive Bayes* -menetelmää aineiston luokittelemiseksi.\n",
    "\n",
    "Ennnusta testiaineiston luokka. Tallenna ennusteet `y_pred`-muuttujaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:47:20.459680Z",
     "start_time": "2024-08-21T11:47:20.435733Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# TODO: Kirjoita toteutuksesi tähän soluun.\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:47:20.490585Z",
     "start_time": "2024-08-21T11:47:20.468647Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "answer_3_2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "# Tehtävän vastaukset. Huom! Älä muokkaa tätä solua, vaan aja se, kun olet suorittanut tehtävän. \n",
    "# Tallenna ennusteen tulokset y_pred-muuttujaan.\n",
    "print(f'{len(y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tehtävä 3.3\n",
    "### Aihe: Tarkkuuden mittaaminen (2 pistettä)\n",
    "\n",
    "Hyödynnä `scikit-learn`-kirjaston `metrics`-moduulin funktioita ja laske luokittelutuloksesi **tarkkuus** sekä **sekaannusmatriisi**. Tallenna tarkkuus muuttujaan `acc` ja sekaannusmatriisi muuttujaan `cm`. \n",
    "\n",
    "* Vinkki: onnistumista voit mitata ainoastaan testiaineiston osalta!\n",
    "* Vinkki: Tässä tehtävässä sekaannusmatriisi ja luokittelutuloksen tarkkuus luultavasti kohtalaisen hyviä (90 % -100 % välissä)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:47:20.521503Z",
     "start_time": "2024-08-21T11:47:20.498565Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Kirjoita toteutuksesi tähän soluun.\n",
    "acc = cm = None\n",
    "# TODO: luokittelutuloksesi tarkkuus sekä sekaannusmatriisi (confusion matrix)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T11:47:20.550424Z",
     "start_time": "2024-08-21T11:47:20.526490Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "answer_3_3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion matrix:\n",
      " [[24  0  0]\n",
      " [ 0 18  0]\n",
      " [ 0  0 17]]\n"
     ]
    }
   ],
   "source": [
    "# Tehtävän vastaukset. Huom! Älä muokkaa tätä solua, vaan aja se, kun olet suorittanut tehtävän. \n",
    "# Tallenna vastauksesi acc- ja cm-muuttujiin.\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'Confusion matrix:\\n {cm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tehtävä 3.4\n",
    "### Aihe: Tulosten tulkinta (2 pistettä)\n",
    "\n",
    "**Miksi tuloksia tulkitaan?** Tulosanalyysi on äärimmäisen tärkeää koneoppimisessa. Pelkkä (hyväkään) ratkaisu ei usein sellaisenaan riitä, vaan tulosten merkitys pitää ymmärtää \"liiketoiminnan\" kannalta.\n",
    "\n",
    "Tulkitse sanallisesti saadut testitulokset.\n",
    "Kuinka hyvin luokittelu onnistui? Pohdi myös miten valittu koneoppimismenetelmä toimi tässä tehtävässä.\n",
    "\n",
    "* Vinkki: Jos sinulla riittää motivaatiota, niin kokeile ainakin jotakin muuta luokittelumenetelmää tässä tehtävässä. Tämä samalla varmistaa sen, että tässä tehtävässä saadut tulokset ovat \"riittävän hyvät\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "Accuracy: 0.9830508474576272\n",
      "Confusion matrix:\n",
      " [[24  0  0]\n",
      " [ 0 18  0]\n",
      " [ 0  1 16]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = 8\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(f'{len(knn_pred)}')\n",
    "\n",
    "# TODO: Kirjoita toteutuksesi tähän soluun.\n",
    "acc_knn = cm_knn = None\n",
    "# TODO: luokittelutuloksesi tarkkuus sekä sekaannusmatriisi (confusion matrix)\n",
    "acc_knn = accuracy_score(y_test, knn_pred)\n",
    "cm_knn = confusion_matrix(y_test, knn_pred)\n",
    "\n",
    "print(f'Accuracy: {acc_knn}')\n",
    "print(f'Confusion matrix:\\n {cm_knn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Vastaus: Tulosten tulkinta\n",
    "\n",
    "* TODO: TULOSTEN SANALLISTA TULKINTAA VASTATEN KYSYMYKSIIN, JOITA TEHTÄVÄSSÄ ESITETTY\n",
    "* TODO: MUUTAKIN SAA TÄHÄN KOMMENTOIDA TEHTÄVÄÄN LIITTYEN.\n",
    "\n",
    "Pohdinnan rivimäärä ei ole ratkaisevaa, mutta harvemmin riittää 1-2 riviä tekstiä, jos tehtävän tuloksia lähtee oikeasti miettimään! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tämä lähti vähän käsistä. Muutenkin kiirettä moduulivaihdon takia, mutta alkoi kiinnostamaan. Toivottavasti edes vastasin oikeisiin kysymyksiin.\n",
    "\n",
    "## Mitä teimme?\n",
    "\n",
    "Ensin lisäsimme kolumneille otsikot. Tämän jälkeen tiputimme Xltä \"oikean vastausrivin\" ja lisäsimme sen y:lle\n",
    "Muodostimme koulutus ja ennustus dataframet. Koulutukseen käytettiin 119 näytettä ja niitten perusteella\n",
    "ennustettiin 59 näytettä. (66/33 split)\n",
    "\n",
    "Käytimme X_train ja y_train dataa koulutukseen ja ennustimme X_test näytteille luokkamuuttujat. Tästä tuloksesta\n",
    "tuli muuttuja y_pred ja tämä sai 59 ennustettua arvoa.\n",
    "\n",
    "Käytimme accuracy_score ja confusion_matrix työkaluja arvioimaan mallin oikeellisuutta.\n",
    "Työkalut vertasivat ennustettuja y_pred arvoja y_test arvoihin. y_test sisältää oikeat luokkamuuttujat.\n",
    "\n",
    "Accurary = 1.0, eli kaikki ennustamamme näytteet olivat oikeissa luokkamuuttujissaan.\n",
    "Confusion matrix osoitti vielä visuaalisesti meille tulosten oikeellisuuden.\n",
    "\n",
    "Teimme samat temput knn koneoppimismallilla. (Toivottavasti tajusin vinkki tehtävän oikein)\n",
    "\n",
    "knn antoi tarkkuudeksi 0.9830508474576272 ja confusion matrix varmisti tämän.\n",
    "\n",
    "Confusion matrix:\n",
    " [[24  0  0]\n",
    " [ 0 18  0]\n",
    " [ 0  1 16]]\n",
    "\n",
    "x-akseli = ennustettu luokka ja y-akseli = todellinen luokka.\n",
    "Tämä tarkoittaa, että yksi luokan 3 arvo ennustettiin väärin luokkaan 2.\n",
    "\n",
    "## Vastausten pohdinta\n",
    "\n",
    "Tarkastetaan ensin yksinkertaisella esimerkillä miten gnb toimii:\n",
    "\n",
    "Otetaan kaksi viiniä joistain alueista. Tässä on kaksi viiniä alueelta 2 ja kaksi viiniä alueelta 3.\n",
    "Katson vain alkoholipitoisuuksia, sillä muuten tästä tulisi liian sekavaa ja pitkää.\n",
    "\n",
    "Laskin kaavoja paperille mutta tähän kirjaan vastauksia.\n",
    "\n",
    "2,12.37\n",
    "2,12.04\n",
    "3,12.86\n",
    "3,12.88\n",
    "\n",
    "Lasketaan keskiarvot ja keskihajonnat alueille:\n",
    "\n",
    "keskiarvo alueella 2: 12.205\n",
    "keskihajonta: 0.26\n",
    "\n",
    "keskiarvo alueella 3: 12.87\n",
    "keskihajonta: 0.01\n",
    "\n",
    "P(12.5 | Alue2) = 0.808\n",
    "P(12.5 | Alue3) = (1/0.02507)exp(-684.5)\n",
    "\n",
    "Oma suomennos: P(12.5 | Alue3) = kuinka usein 12.5 alkoholipitoisuus tapahtuu kun Alue3 tapahtuu\n",
    "= Kuinka todennäköistä on että 12.5 on alueella 3\n",
    "(1/0.02507)exp(-684.5) = näin suuri negatiivinen exponentin arvo on *hyvin* lähellä nollaa,\n",
    "joten voimme todeta että 12.5 alkoholipitoinen viini ei ole alueelta 3 ja tässä esimerkissä se olisi alueelta 2.\n",
    "\n",
    "Jokaiselle viinin ominaisuudelle tehdään sama prosessi ja viinit osataan luokitella alueille kun kone on oppinut\n",
    "alueiden ominaisuudet harjoitteludatalla.\n",
    "\n",
    "## Miksi GNB toimii niin hyvin tässä?\n",
    "\n",
    "- Datan eri ominaisuudet eivät ole vahvasti riippuvaisia toisistaan (ainakaan ymmärtääkseni, en ole viiniexpertti :D)\n",
    "\n",
    "- Datan ominaisuudet ovat enimmäkseen keskittyneet keskiarvon ympärille (normaalijakauma)\n",
    "\n",
    "- Selkeät erot luokkien välillä, tosin ei ehkä silmällä vilkaistuna\n",
    "\n",
    "## Miksi GNB voitti KNN?\n",
    "\n",
    "KNN ei ollut huono, se sai myös hyvin ennustettua testidatan luokat. En osaa kunnolla vastata tähän,\n",
    "ehkä tulos ei ollut knn:n huonoutta, vaan yksinkertaisesti data sopi niin hyvin gnb:elle?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
